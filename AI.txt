import copy
import argparse
import sys
import math
import os
sys.path.append(os.path.abspath("c:/sbr/아무거나/jupyternotebook_for_AI/Holistic"))
import cv2
import time
import datetime
import HolisticModule as hm
from win10toast import ToastNotifier
import math
import time

""
sensitivity = 8
""

# 데이터 리스트 만들기
data = []
turn_head = []
head_down = []
secession = []
a = 0
b = 0
c = 0
d = 0
e = 0
k = 0

# video input 
cap = cv2.VideoCapture(0)

# Holistic 객체(어떠한 행위를 하는 친구) 생성
detector = hm.HolisticDetector()

# turtle_neck_count 변수 초기 세팅
turtle_neck_count = 0
i = time.time()
m = i

while True:
    # defalut BGR img
    success, img = cap.read()

    # mediapipe를 거친 이미지 생성 -> img
    img = detector.findHolistic(img, draw=False)

    # output -> list ( id, x, y, z) 32 개 좌표인데 예를 들면, (11, x, y, z)
    pose_lmList = detector.findPoseLandmark(img, draw=False)
    # 468개의 얼굴 점 리스트
    face_lmList = detector.findFaceLandmark(img, draw=False)
    

    # 인체가 감지가 되었는지 확인하는 구문
    if len(pose_lmList) != 0 and len(face_lmList) != 0:        

        # 양 어깨 좌표 11번과 12번의 중심 좌표를 찾아 낸다.
        center_shoulder = detector.findCenter(11,12)

        # 목 길이 center_shoulder 좌표와 얼굴 152번(턱) 좌표를 사용하여 길이 구하는 부분
        # 목 길이가 표시된 이미지로 변경
        length, img = detector.findDistance(152, center_shoulder, img, draw=False)

        # x, y, z좌표 예측 (노트북 웹캠과의 거리를 대강 예측) - 노트북과의 거리
        pose_depth = abs(500 - detector.findDepth(11,12)) 
     
        if pose_depth > 0:
            # 목 위치ㅣ 감지 임계치
            turtleneck_detect_threshold = abs(math.log2(pose_depth)) * sensitivity
        # 노트북과의 거리가 아주 가까운 상태
        else:
            turtleneck_detect_threshold = 50      
    
        # 핵심 로직: 목 길이가 임계치보다 작을 때와 클 때로 나누어 구분한다.
        if length < (turtleneck_detect_threshold - 10):
            turtle_neck_count += 1                
        elif length > (turtleneck_detect_threshold + 10):
            turtle_neck_count += 1
        
        
        # 프레임 단위가 16 이상이면, 고개를 움직인 것으로 인식되고 결과를 출력한다. 
        if length > (turtleneck_detect_threshold + 10) and turtle_neck_count > 15: 
            now = datetime.datetime.now()
            turn_head.append(now.strftime('%Y%m%d %H:%M:%S'))           
            print("수업에 집중해주세요.")
            print(now)  
            # 알림 제공 후 카운트를 다시 0으로 만든다.
            turtle_neck_count = 0
            a += 1
            print(a)
            k = time.time()          
                     
        elif length < (turtleneck_detect_threshold - 10) and turtle_neck_count > 15:
            now = datetime.datetime.now()
            head_down.append(now.strftime('%Y%m%d %H:%M:%S'))
            print("고개를 아래로 내리는 중")
            print(now)             
            # 알림 제공 후 카운트를 다시 0으로 만든다.
            turtle_neck_count = 0
            b += 1
            print(b)
            k = time.time()
     
    # 사람이 인식되지 않을 때(자리비움)
    else :
        now = datetime.datetime.now()
        secession.append(now.strftime('%Y%m%d %H:%M:%S'))
        time.sleep(1)
        c += 1
        k = time.time()
    
    # 데이터 전처리
    l = k + 1
    
    if (a < 20 or b < 20 or c < 20) and l-k >2:
        a = 0
        b = 0
        c = 0
    
    if a == 20:
        d += 1
        a = 0
        l = time.time()

    if b == 20:
        d += 1
        a = 0
        l = time.time()

    if c == 20:
        d += 1
        a = 0
        l = time.time()

    elif (a + b + c) == 20 :
        d +=1
        a = 0
        b = 0
        c = 0
        l = time.time()

    # 10분 단위로 계산하기
    n = time.time()
    
    if n - i >= 600 :
        i = n
        d = 0
        print('이제 d는 0, 10분 지났다')
        
    
    # 데이터 리스트 만들기
    data = [turn_head, head_down, secession]
    
    cv2.imshow("Image", img)
    
    # ESC 키를 눌렀을 때 창을 모두 종료하는 부분
    if cv2.waitKey(1) & 0xFF == 27:
        break 
cap.release()
cv2.destroyAllWindows()